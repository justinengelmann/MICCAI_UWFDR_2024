{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca3cbd-6807-4423-828e-c45c21df8a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from uwf_data import get_dataloaders\n",
    "from timm.utils import ModelEmaV2\n",
    "\n",
    "# Configuration dictionary\n",
    "config = {\n",
    "    \"dataset\": \"tsk1\",\n",
    "    \"model_name\": 'mobilenetv3_rw',\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 5,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 1e-2,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"targets\": ['image quality level'],\n",
    "    \"mixed_precision\": False,\n",
    "    \"dtype\": torch.bfloat16,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"resolution\": (254, 200),\n",
    "    \"aug_type\": \"quality_rev3\",\n",
    "    \"aug_prob\": 0.95,\n",
    "    \"grad_clip_norm\": 1.0,\n",
    "    \"label_smoothing_min_max\": (0.001, 0.999),\n",
    "    \"model_to_load\": None,\n",
    "    \"uwf_task1_extra_augs\": True,\n",
    "    \"uwf_task1_synthetic_bad_only\": False,\n",
    "    \"use_ema\": True,\n",
    "    \"ema_decay\": 0.99,\n",
    "    \"ema_start_epoch\": 1,\n",
    "    \"n_folds\": 30,\n",
    "    \"cv_index\": 0,\n",
    "}\n",
    "config[\"num_classes\"] = len(config[\"targets\"])\n",
    "\n",
    "df = pd.read_csv('uwf_task1_labels.csv')\n",
    "skf = StratifiedKFold(n_splits=config[\"n_folds\"], shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(df, df['image quality level'])):\n",
    "    if fold == config[\"cv_index\"]:\n",
    "        train_ids = df.iloc[train_index]['image'].values\n",
    "        val_ids = df.iloc[val_index]['image'].values\n",
    "        break\n",
    "\n",
    "train_df = df[df.image.isin(train_ids)].copy()\n",
    "if config['uwf_task1_synthetic_bad_only']:\n",
    "    train_df_to_use = train_df[train_df['image quality level']==1].copy()\n",
    "else:\n",
    "    train_df_to_use = train_df\n",
    "val_df = df[df.image.isin(val_ids)]\n",
    "\n",
    "train_loader, val_loader = get_dataloaders(train_df_to_use, val_df, target_cols=config[\"targets\"], batch_size=config['batch_size'],\n",
    "                                           uwf_task1_extra_augs=config['uwf_task1_extra_augs'],\n",
    "                                           res=config[\"resolution\"], aug_type=config[\"aug_type\"], aug_prob=config[\"aug_prob\"])\n",
    "print(len(train_loader.dataset))\n",
    "\n",
    "current_time = datetime.now().strftime(\"%m%d%H%M%S\")\n",
    "res_str = f\"{config['resolution'][0]}x{config['resolution'][1]}\"\n",
    "save_name = f\"miccai24/uwf_runs/{config['dataset']}_{config['model_name']}_{res_str}_{current_time}_fold{config['cv_index']}\"\n",
    "if config['uwf_task1_extra_augs']:\n",
    "    save_name+='extraaug'\n",
    "    if config['uwf_task1_synthetic_bad_only']:\n",
    "        save_name+='synth_only'\n",
    "save_name = save_name.replace('efficientnet', 'efn').replace('resnet', 'rn').replace('mobilenet', 'mn').replace('densenet', 'dn')\n",
    "save_path = Path(save_name)\n",
    "save_path.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"Training started. Save name: {save_name}\")\n",
    "joblib.dump(config, save_path/f'config.joblib')\n",
    "\n",
    "model = timm.create_model(config[\"model_name\"], pretrained=True, num_classes=config[\"num_classes\"])\n",
    "if config['model_to_load']:\n",
    "    state_dict = torch.load('miccai24/uwf_runs/model_to_load/final_model.pth')\n",
    "    try:\n",
    "        model = timm.create_model(config[\"model_name\"], pretrained=False, num_classes=config[\"num_classes\"])\n",
    "        config[\"model_name\"] = state_dict[\"model_name\"]\n",
    "    except:\n",
    "        pass\n",
    "    if state_dict.get('conv1.weight', torch.zeros([1,1])).shape[1] == 2:\n",
    "        with torch.no_grad():\n",
    "            state_dict['conv1.weight'] = torch.concat([state_dict['conv1.weight'], torch.zeros((64,1,7,7))], dim=1)    \n",
    "    _keys_to_del = [k for k in state_dict.keys() if any([k.startswith('fc'), k.startswith('classifier')])]\n",
    "    for k in _keys_to_del:\n",
    "        del state_dict[k]\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    del state_dict\n",
    "\n",
    "with torch.no_grad():\n",
    "    per_target_means = torch.special.logit(torch.tensor(train_df[config['targets']].mean(axis=0).values))\n",
    "    try:\n",
    "        model.fc.weight.fill_(0.)\n",
    "        model.fc.bias.data = torch.nn.Parameter(per_target_means.float())\n",
    "    except:\n",
    "        model.classifier.weight.fill_(0.)\n",
    "        model.classifier.bias.data = torch.nn.Parameter(per_target_means.float())\n",
    "\n",
    "model = model.to(config[\"device\"])\n",
    "\n",
    "ema_model = None\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "if config[\"optimizer\"] == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "elif config[\"optimizer\"] == \"AdamW\":\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported optimizer: {config['optimizer']}\")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=config[\"mixed_precision\"])\n",
    "ls_min, ls_max = config['label_smoothing_min_max']\n",
    "\n",
    "best_val_loss = np.inf\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "main_pbar = tqdm(range(config[\"epochs\"]), desc=\"Epochs\")\n",
    "for epoch in main_pbar:\n",
    "    if config[\"use_ema\"] and epoch >= config[\"ema_start_epoch\"]:\n",
    "        if ema_model is None:\n",
    "            print('Initialising EMA')\n",
    "            ema_model = ModelEmaV2(model, decay=config[\"ema_decay\"])\n",
    "        \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Train\", leave=False)\n",
    "    for batch in pbar:\n",
    "        inputs = batch['image']\n",
    "        targets = batch['target'].clamp(ls_min, ls_max)\n",
    "        inputs, targets = inputs.to(config[\"device\"]), targets.to(config[\"device\"])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(enabled=config[\"mixed_precision\"], dtype=config[\"dtype\"]):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets.float())\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        if config[\"grad_clip_norm\"] > 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config[\"grad_clip_norm\"])\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        if ema_model:\n",
    "            ema_model.update(model)\n",
    "        \n",
    "        epoch_loss += loss.item() * inputs.size(0)\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "        all_predictions.extend(outputs.float().squeeze().detach().cpu().numpy())\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            \"loss\": f\"{loss.item():.4f}\",\n",
    "            \"mem\": f\"{torch.cuda.max_memory_allocated() / 1e9:.2f}GB\"\n",
    "        })\n",
    "    \n",
    "    epoch_loss /= len(train_loader.dataset)\n",
    "    epoch_auc = roc_auc_score(np.hstack(all_targets)>0.5, all_predictions)\n",
    "    train_metrics.append({\"loss\": epoch_loss, \"auc\": epoch_auc})\n",
    "        \n",
    "    model.eval()\n",
    "    if ema_model:\n",
    "        ema_model.eval()\n",
    "    val_loss = 0\n",
    "    ema_val_loss = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    ema_all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Val\", leave=False):\n",
    "            inputs = batch['image']\n",
    "            targets = batch['target']\n",
    "            inputs, targets = inputs.to(config[\"device\"]), targets.to(config[\"device\"])\n",
    "            \n",
    "            with torch.cuda.amp.autocast(enabled=config[\"mixed_precision\"], dtype=config[\"dtype\"]):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets.float())\n",
    "                \n",
    "                if ema_model:\n",
    "                    ema_outputs = ema_model.module(inputs)\n",
    "                    ema_loss = criterion(ema_outputs, targets.float())\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            if ema_model:\n",
    "                ema_val_loss += ema_loss.item() * inputs.size(0)\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(outputs.float().squeeze().detach().cpu().numpy())\n",
    "            if ema_model:\n",
    "                ema_all_predictions.extend(ema_outputs.float().squeeze().detach().cpu().numpy())\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_auc = roc_auc_score(np.hstack(all_targets)>0.5, all_predictions)\n",
    "    val_metrics.append({\"loss\": val_loss, \"auc\": val_auc})\n",
    "    \n",
    "    ep_str = f\"Ep {epoch} Train L: {epoch_loss:.4f} AUC: {epoch_auc:.4f} Val L: {val_loss:.4f} AUC: {val_auc:.4f}\"\n",
    "\n",
    "    if ema_model:\n",
    "        ema_val_loss /= len(val_loader.dataset)\n",
    "        ema_val_auc = roc_auc_score(np.hstack(all_targets)>0.5, ema_all_predictions)\n",
    "        ep_str += f\" EMA L: {ema_val_loss:.4f} AUC: {ema_val_auc:.4f}\"\n",
    "\n",
    "    print(ep_str)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        sd = model.state_dict()\n",
    "        sd[\"model_name\"] = config[\"model_name\"]\n",
    "        sd[\"resolution\"] = config['resolution']\n",
    "        torch.save(sd, save_path/f'best_model.pth')\n",
    "    \n",
    "    if ema_model and ema_val_loss < best_val_loss:\n",
    "        best_val_loss = ema_val_loss\n",
    "        sd = ema_model.module.state_dict()\n",
    "        sd[\"model_name\"] = config[\"model_name\"]\n",
    "        sd[\"resolution\"] = config['resolution']\n",
    "        torch.save(sd, save_path/f'best_ema_model.pth')\n",
    "\n",
    "    main_pbar.set_postfix({\n",
    "        \"loss\": f\"{epoch_loss:.4f}\",\n",
    "        \"mem\": f\"{torch.cuda.max_memory_allocated() / 1e9:.2f}GB\"\n",
    "    })\n",
    "\n",
    "sd = model.state_dict()\n",
    "sd[\"model_name\"] = config[\"model_name\"]\n",
    "sd[\"resolution\"] = config['resolution']\n",
    "torch.save(sd, save_path/f'final_model.pth')\n",
    "\n",
    "if ema_model:\n",
    "    sd = ema_model.module.state_dict()\n",
    "    sd[\"model_name\"] = config[\"model_name\"]\n",
    "    sd[\"resolution\"] = config['resolution']\n",
    "    torch.save(sd, save_path/f'final_ema_model.pth')\n",
    "\n",
    "joblib.dump({\n",
    "    \"train_metrics\": train_metrics,\n",
    "    \"val_metrics\": val_metrics\n",
    "}, save_path/f'metrics.joblib')\n",
    "\n",
    "print(f\"Training completed. Final model and metrics saved with prefix: {save_name}\")\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Regular model submissions\n",
    "shutil.copy(save_path/f'final_model.pth', 'TemplateSubmission/')\n",
    "shutil.make_archive('submissions/T1'+save_path.name, 'zip', 'TemplateSubmission/')\n",
    "\n",
    "shutil.copy(save_path/f'best_model.pth', 'TemplateSubmission/final_model.pth')\n",
    "shutil.make_archive('submissions/bT1'+save_path.name, 'zip', 'TemplateSubmission/')\n",
    "\n",
    "# EMA model submissions\n",
    "if config[\"use_ema\"]:\n",
    "    shutil.copy(save_path/f'final_ema_model.pth', 'TemplateSubmission/final_model.pth')\n",
    "    shutil.make_archive('submissions/T1EMA'+save_path.name, 'zip', 'TemplateSubmission/')\n",
    "    try:\n",
    "        shutil.copy(save_path/f'best_ema_model.pth', 'TemplateSubmission/final_model.pth')\n",
    "        shutil.make_archive('submissions/bT1EMA'+save_path.name, 'zip', 'TemplateSubmission/')\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print(\"All submissions prepared, including EMA models if applicable.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
